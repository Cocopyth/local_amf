{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c80be-987f-4332-8255-b30b9bae5afb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import re\n",
    "import dropbox\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from subprocess import call\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_folders_prince,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis,\n",
    ")\n",
    "from amftrack.util.dbx import upload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from amftrack.transport.align_video_network import identify_nodes\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.register_videos import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88104-cf1c-4cbe-afa1-093e6686e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id = \"310_20230830\"\n",
    "plate_id_video = \"20230904_Plate310\"\n",
    "videos_folder = \"/projects/0/einf914/videos/\"\n",
    "plate_id = \"441_20230807\"\n",
    "plate_id_video = \"20230810_Plate441\"\n",
    "videos_folder = \"/projects/0/einf914/videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a22211-6911-468a-bdfb-868110775800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = {\n",
    "    \"20230901_Plate310\": 20,\n",
    "    \"20230902_Plate310\": 33,\n",
    "    \"20230903_Plate310\": 42,\n",
    "    \"20230904_Plate310\": 52,\n",
    "    \"20230905_Plate310\": 64,\n",
    "    \"20230906_Plate310\": 73,\n",
    "}\n",
    "indexes = {\n",
    "    \"20230810_Plate441\": \"20230810_1005_Plate14\",\n",
    "    \"20230811_Plate441\": \"20230811_1605_Plate14\",\n",
    "    \"20230812_Plate441\": \"20230812_1006_Plate14\",\n",
    "    \"20230813_Plate441\": \"20230812_1618_Plate14\",\n",
    "}\n",
    "indexes = {\n",
    "    \"20230813_Plate449\": \"20230813_1606_Plate10\",\n",
    "    \"20230814_Plate449\": \"20230814_1019_Plate10\",\n",
    "    \"20230815_Plate449\": \"20230815_1021_Plate10\",\n",
    "    \"20230816_Plate449\": \"20230816_1027_Plate10\",\n",
    "    \"20230818_Plate449\": \"20230818_1107_Plate10\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755db006-2e57-49ae-86e0-79730f9b8dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder = \"/projects/0/einf914/analysis_videos/CocoTransport/\"\n",
    "analysis_folder = f\"{analysis_folder}{plate_id_video}/\"\n",
    "\n",
    "img_infos = glob.glob(f\"{analysis_folder}/**/video_data.json\", recursive=True)\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "add_infos = []\n",
    "for address in img_infos:\n",
    "    add_infos.append(pd.read_json(address, orient=\"index\").T)\n",
    "vid_anls_frame = pd.concat([vid_anls_frame] + add_infos, ignore_index=True)\n",
    "\n",
    "vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "vid_anls_frame_select = vid_anls_frame.loc[vid_anls_frame[\"plate_id\"] == plate_id_video]\n",
    "columns_to_drop = [\"xpos_network\", \"ypos_network\"]\n",
    "\n",
    "# Dropping columns from vid_anls_frame_select_network if they exist\n",
    "for column in columns_to_drop:\n",
    "    if column in vid_anls_frame_select.columns:\n",
    "        vid_anls_frame_select = vid_anls_frame_select.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190395ee-6c25-4d1a-8e25-6ab0756d77a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder = \"/projects/0/einf914/analysis_videos/CocoTransport/\"\n",
    "analysis_folder = f\"{analysis_folder}{plate_id_video}/\"\n",
    "\n",
    "img_infos = glob.glob(f\"{analysis_folder}/**/video_data_network.json\", recursive=True)\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "add_infos = []\n",
    "for address in img_infos:\n",
    "    add_infos.append(pd.read_json(address, orient=\"index\").T)\n",
    "vid_anls_frame = pd.concat([vid_anls_frame] + add_infos, ignore_index=True)\n",
    "\n",
    "vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "vid_anls_frame_select_network = vid_anls_frame.loc[\n",
    "    vid_anls_frame[\"plate_id\"] == plate_id_video\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd003a92-2802-4eba-ae67-6b2e66eb6f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_anls_frame_merged = vid_anls_frame_select.merge(\n",
    "    vid_anls_frame_select_network[[\"xpos_network\", \"ypos_network\", \"unique_id\"]],\n",
    "    on=\"unique_id\",\n",
    ")\n",
    "# vid_anls_frame_merged = vid_anls_frame_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cde5f8-0af4-4234-8244-18df636b5e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vid_anls_frame_merged['folder'] = vid_anls_frame_merged['folder'].str.replace('/Img','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce99f8-b0d4-4049-a521-cc716dc84e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder_root = \"/projects/0/einf914/analysis_videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ebbd1-52f6-4767-aa91-2a2cbeaeae26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_anls_frame_merged[\"analysis_folder\"] = analysis_folder_root\n",
    "vid_anls_frame_merged[\"videos_folder\"] = [\n",
    "    str(Path(videos_folder) / entry[\"folder\"])\n",
    "    for index, entry in vid_anls_frame_merged.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535df95-c0e8-4153-9a02-615bf4db8485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_obj = HighmagDataset(vid_anls_frame_merged, analysis_folder_root, videos_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515db227-60eb-4f6a-8b79-e6b6d7a2658c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directory_targ = os.path.join(directory_scratch, \"stitch_temp2\") + \"/\"\n",
    "directory_targ = \"/projects/0/einf914/transport/\"\n",
    "update_plate_info(directory_targ, local=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcaf393-92d6-42fe-bd10-dfd64a496391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_folders[\"unique_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54265cf6-9ab6-4d8e-bd26-85929d63ab06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plate_id]\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5de02-b0e9-4562-8039-eed259d064fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ae46-8df7-4ef7-b5e6-797ac49747fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "i = np.where(folders[\"folder\"] == indexes[plate_id_video])[0][0]\n",
    "exp.load(folders.iloc[i : i + 1], suffix=\"_width\")\n",
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fef5c-e1c7-49fb-8a8a-5cb20c00a8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_obj.video_objs = sorted(\n",
    "    data_obj.video_objs, key=lambda video: video.dataset[\"video_int\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dd667-5995-4eda-8a57-b4ec35d4c554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 50\n",
    "\n",
    "from random import choice\n",
    "\n",
    "vid_obj = choice(data_obj.video_objs)\n",
    "vid_obj = data_obj.video_objs[95]\n",
    "\n",
    "vid_obj.plot_speed_arrows(plot_both=True, video_txt_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f571935-ad47-49a0-a6e5-136263a31c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent, tcurrent = np.array([[1, 0], [0, 1]]), np.array([0, 0])\n",
    "\n",
    "Rcurrent, tcurrent, mapping, dist = process_video_object(\n",
    "    vid_obj, exp, t, Rcurrent, tcurrent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7b45e-94f5-4e83-9e56-d88d9673f9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f519b6e-dce9-4c70-8467-bf2bb0d91f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rcurrent,tcurrent = np.array([[1,0],[0,1]]), np.array([0 ,0])\n",
    "\n",
    "positions = (\n",
    "    Rcurrent @ np.array(vid_obj.dataset[[\"xpos_network\", \"ypos_network\"]]) + tcurrent\n",
    ")\n",
    "positions_list = [positions.tolist()]\n",
    "window = np.array([100, 100])\n",
    "begin = (positions - window).astype(int)\n",
    "end = (positions + window).astype(int)\n",
    "region = [[begin[0], begin[1]], [end[0], end[1]]]\n",
    "# region = [[100, 100], [2000,2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03660efe-f6f8-41a9-9fd3-5e54ba2c0a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124b186-28d9-48de-bd3c-1491d18acccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shiftx = vid_obj.img_dim[0] * vid_obj.space_res / 1.725 / 2\n",
    "shifty = vid_obj.img_dim[1] * vid_obj.space_res / 1.725 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04027ec0-14e2-40b2-97fc-1f19c29121e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segments = get_segments_ends(vid_obj, shiftx, shifty, 20, Rcurrent, tcurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceaf751-7a5f-4eac-86b3-4dcf72f56dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = get_all_edges(exp, t)\n",
    "\n",
    "edges = [edge for edge in edges if dist_edge(edge, positions, t) <= 100]\n",
    "pixels = [pixel for edge in edges for pixel in edge.pixel_list(t)]\n",
    "pixels = [pixel for pixel in pixels if np.linalg.norm(pixel - positions) <= 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd13782-0d6c-4032-8963-2cbc331e97e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segment_points = []\n",
    "for begin, end in segments:\n",
    "    # Include the start point, interpolated points, and the end point\n",
    "    interpolated_points = interpolate_points(begin, end)\n",
    "    segment_points.extend(interpolated_points)\n",
    "    segment_points.append(end)  # Ensure the end point is included\n",
    "\n",
    "segment_points = np.array(segment_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacaa927-5bfb-4acd-ad0d-9d529ceef2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plotting import *\n",
    "\n",
    "positions_list = [positions.tolist()]\n",
    "# plt.close(\"all\")\n",
    "t = 0\n",
    "vmax = 9\n",
    "vmin = 3\n",
    "nodes = get_all_nodes(exp, t)\n",
    "edges = get_all_edges(exp, t)\n",
    "edges = [edge for edge in edges if dist_edge(edge, positions, t) <= 100]\n",
    "downsizing = 1\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=edges,\n",
    "    dilation=5,\n",
    "    region=region,\n",
    "    segments=segments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b2b25-63e8-42b3-af5a-dcf4d8c7c7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting point cloud\n",
    "px, py = zip(*pixels)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"blue\")  # Plot points in blue\n",
    "px, py = zip(*segment_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"red\")  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f5e8d-c6f5-4f6e-9f05-a89947b4a947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = np.array(pixels)\n",
    "X = np.array(segment_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d038f29-ca62-4e32-a21b-7ac819e34abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import probreg as pr\n",
    "\n",
    "# X = np.insert(X, 2, values=0, axis=1)  # Inserting a Z-axis with zero values\n",
    "# Y = np.insert(Y, 2, values=0, axis=1)  # Inserting a Z-axis with zero values\n",
    "\n",
    "# Convert numpy arrays to point clouds.\n",
    "# In probreg, point clouds can be represented directly as numpy arrays.\n",
    "source = X\n",
    "target = Y\n",
    "# reg = cpd.registration(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85d9ba-ead0-4155-9da2-a8dad6df367d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent, tcurrent = find_optimal_R_and_t(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa935e3-e657-4382-9957-4908eae95c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent, tcurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d3727-29f4-4704-8c2f-c39364007c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformation_matrix = np.eye(4)\n",
    "transformation_matrix[:3, :3] = cpd.transformation.rot  # Rotation\n",
    "transformation_matrix[:3, 3] = cpd.transformation.t  # Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54168528-c25b-4573-a22c-863ed19b4fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the source point cloud using the obtained transformation matrix\n",
    "transformed_source = np.dot(R, source.T).T + t\n",
    "\n",
    "# Calculate distances between each pair of corresponding points\n",
    "distances = average_min_distance_to_set(transformed_source, target)\n",
    "\n",
    "# Compute the root mean square deviation\n",
    "rmsd = np.sqrt(np.mean(distances**2))\n",
    "\n",
    "rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e10ca0-a0ef-45cc-adca-c6acb3a7c100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent, tcurrent = cpd.transformation.rot[:2, :2], cpd.transformation.t[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42d1e5-68eb-4c93-80e6-a1177643cae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent, tcurrent = np.array([[1, 0], [0, 1]]), np.array([0, 0])\n",
    "mapping, dist, Rfound, tfound = make_whole_mapping(\n",
    "    vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent\n",
    ")\n",
    "if np.linalg.det(Rfound) > 0:\n",
    "    Rcurrent = Rfound @ Rcurrent\n",
    "    tcurrent = Rfound @ tcurrent + tfound\n",
    "    if dist > 20:\n",
    "        mapping, dist, Rfound, tfound = make_whole_mapping(\n",
    "            vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent\n",
    "        )\n",
    "        if np.linalg.det(Rfound) > 0:\n",
    "            Rcurrent = Rfound @ Rcurrent\n",
    "            tcurrent = Rfound @ tcurrent + tfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34ea09-00c5-4b52-aa69-b1b0eea8675d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.linalg.det(Rfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e83c9-aad6-47cc-82f2-1e0de72c27a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for edge in vid_obj.edge_objs:\n",
    "\n",
    "    edge_data_csv.loc[edge_data_csv[\"edge_name\"] == edge.edge_name, \"width\"] = 2\n",
    "edge_data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf5b27-4bfe-411f-bc13-e704eb80124b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_attribute(\n",
    "    edge_data_csv, vid_edge_obj, network_edge_attribute, name_new_col, mapping\n",
    "):\n",
    "    new_attribute = network_edge_attribute(mapping[vid_edge_obj.edge_name])\n",
    "    # print(new_attribute)\n",
    "    edge_data_csv.loc[\n",
    "        edge_data_csv[\"edge_name\"] == vid_edge_obj.edge_name, name_new_col\n",
    "    ] = new_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15019ef5-9bca-4a1e-a500-c912712c8c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for edge in vid_obj.edge_objs:\n",
    "    add_attribute(edge_data_csv, edge, lambda edge: edge.width(t), \"width\", mapping)\n",
    "    add_attribute(\n",
    "        edge_data_csv, edge, lambda edge: edge.end.label, \"network_end\", mapping\n",
    "    )\n",
    "    add_attribute(\n",
    "        edge_data_csv, edge, lambda edge: edge.begin.label, \"network_begin\", mapping\n",
    "    )\n",
    "    add_attribute(edge_data_csv, edge, lambda edge: dist, \"mapping_quality\", mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1a294-b411-4cb5-a5f0-fa5fa5c6b80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50c7a6-219a-4b80-b39c-eb050d18ea33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def check_hasedges(vid_obj):\n",
    "    shiftx = vid_obj.img_dim[0] * vid_obj.space_res / 1.725 / 2\n",
    "    shifty = vid_obj.img_dim[1] * vid_obj.space_res / 1.725 / 2\n",
    "    segments = get_segments_ends(vid_obj, shiftx, shifty, 40)\n",
    "    return len(segments) > 0\n",
    "\n",
    "\n",
    "def initialize_transformation():\n",
    "    return np.array([[1, 0], [0, 1]]), np.array([0, 0])\n",
    "\n",
    "\n",
    "def update_transformation(Rcurrent, tcurrent, Rfound, tfound):\n",
    "    Rcurrent = Rfound @ Rcurrent\n",
    "    tcurrent = Rfound @ tcurrent + tfound\n",
    "    return Rcurrent, tcurrent\n",
    "\n",
    "\n",
    "def should_reset(Rfound):\n",
    "    return np.linalg.det(Rfound) <= 0 or Rfound[0][0] <= 0.99\n",
    "\n",
    "\n",
    "def attempt_mapping(vid_obj, exp, t, Rcurrent, tcurrent):\n",
    "    try:\n",
    "        mapping, dist, Rfound, tfound = make_whole_mapping(\n",
    "            vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent\n",
    "        )\n",
    "    except IndexError:\n",
    "        Rcurrent, tcurrent = initialize_transformation()\n",
    "        mapping, dist, Rfound, tfound = make_whole_mapping(\n",
    "            vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent\n",
    "        )\n",
    "    return mapping, dist, Rfound, tfound\n",
    "\n",
    "\n",
    "def process_video_object(vid_obj, exp, t, Rcurrent, tcurrent):\n",
    "    mapping, dist, Rfound, tfound = attempt_mapping(vid_obj, exp, t, Rcurrent, tcurrent)\n",
    "    if np.linalg.det(Rfound) > 0 and Rfound[0][0] > 0.99:\n",
    "        Rcurrent, tcurrent = update_transformation(Rcurrent, tcurrent, Rfound, tfound)\n",
    "        if dist > 20:\n",
    "            mapping, dist, Rfound, tfound = attempt_mapping(\n",
    "                vid_obj, exp, t, Rcurrent, tcurrent\n",
    "            )\n",
    "            if should_reset(Rfound):\n",
    "                Rcurrent, tcurrent = initialize_transformation()\n",
    "    else:\n",
    "        Rcurrent, tcurrent = initialize_transformation()\n",
    "    return Rcurrent, tcurrent, mapping, dist\n",
    "\n",
    "\n",
    "def register_dataset(data_obj, exp, t):\n",
    "    Rcurrent, tcurrent = initialize_transformation()\n",
    "\n",
    "    for index, vid_obj in enumerate(data_obj.video_objs[35:]):\n",
    "        if check_hasedges(vid_obj):\n",
    "            Rcurrent, tcurrent, mapping, dist = process_video_object(\n",
    "                vid_obj, exp, t, Rcurrent, tcurrent\n",
    "            )\n",
    "            print(index, dist, Rcurrent, tcurrent)\n",
    "            update_edge_attributes(vid_obj, mapping, dist, t)\n",
    "\n",
    "\n",
    "def update_edge_attributes(vid_obj, mapping, dist, t):\n",
    "    edge_data_csv = pd.read_csv(vid_obj.edge_adr)\n",
    "    for edge in vid_obj.edge_objs:\n",
    "        add_attribute(edge_data_csv, edge, lambda edge: edge.width(t), \"width\", mapping)\n",
    "        add_attribute(\n",
    "            edge_data_csv, edge, lambda edge: edge.end.label, \"network_end\", mapping\n",
    "        )\n",
    "        add_attribute(\n",
    "            edge_data_csv, edge, lambda edge: edge.begin.label, \"network_begin\", mapping\n",
    "        )\n",
    "        add_attribute(\n",
    "            edge_data_csv, edge, lambda edge: dist, \"mapping_quality\", mapping\n",
    "        )\n",
    "    edge_data_csv.to_csv(vid_obj.edge_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32764354-77cb-48ac-816f-d07dd352be04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_dataset(data_obj, exp, t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
