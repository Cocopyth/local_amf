{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88220c9b-d582-42c5-ba3d-4a51f32874e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from amftrack.util.sys import get_analysis_folders,get_time_plate_info_from_analysis,get_time_hypha_info_from_analysis,get_global_hypha_info_from_analysis, get_time_plate_info_long_from_analysis\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import cv2\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from amftrack.pipeline.final_analysis.density_wave import get_wave_fit, S, dS, wave, dwave\n",
    "import matplotlib.patches as mpatches\n",
    "from random import choice\n",
    "import matplotlib as mpl\n",
    "from amftrack.pipeline.final_analysis.density_wave import plot_single_plate,plot_single_plate_biovolume\n",
    "from amftrack.pipeline.final_analysis.hypha_speed_analysis import *\n",
    "from amftrack.util.plot import gridplot, make_stat\n",
    "%store -r path_figure\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import hashlib\n",
    "from matplotlib.patches import Ellipse\n",
    "import logging\n",
    "plt.style.use('presentation.mplstyle')\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "all_analysis_folders = get_analysis_folders()\n",
    "#for P\n",
    "plates = [\n",
    "\"416_20230705\",\n",
    "\"427_20230707\",\n",
    "\"420_20230705\",\n",
    "\"431_20230627\",\n",
    "\"474_20230807\",\n",
    "\"460_20230807\",\n",
    "\"464_20230807\",\n",
    "\"440_20230723\",\n",
    "\"436_20230717\",\n",
    "\"443_20230720\",\n",
    "\"439_20230804\",\n",
    "\"470_20230709\",\n",
    "'478_20230814', '468_20230809', '447_20230821', '487_20230922',\n",
    "       '492_20230901', '471_20230821', '486_20231009',\n",
    "       '494_20230908', '482_20230908', '495_20231013', '463_20231013',\n",
    "       '491_20231013', '481_20231005', '483_20231005',\n",
    "    '490_20231003',\n",
    "       '485_20230929',\n",
    "]\n",
    "analysis_folders = all_analysis_folders.loc[all_analysis_folders['unique_id'].isin(plates)]\n",
    "path_figure = r\"C:\\Users\\coren\\Documents\\PhD\\paper\\PandC\\Fig3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986351b8-85fd-4de3-ae1d-56f6d7f54313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders,time_plate_info = get_time_plate_info_from_analysis(analysis_folders,False)\n",
    "folders,time_plate_info = get_time_plate_info_long_from_analysis(analysis_folders,False)\n",
    "time_plate_info['unique_id'] = time_plate_info['unique_id'].replace(47020230709,47020230802)\n",
    "time_plate_info=time_plate_info[time_plate_info['Plate']!=431]\n",
    "# time_plate_info['time_since_begin_hour'] = time_plate_info['time_since_begin_h'].dt.total_seconds() / 3600.0\n",
    "# time_plate_info['time_since_begin_hour'] = time_plate_info['time_since_begin_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956c796-be74-4540-9725-2880279808ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "columns_to_check = [f'SA_region_{i}' for i in range(18)] + [f'length_density_region_{i}' for i in range(18)]\n",
    "\n",
    "# Filter DataFrame rows where any of the specified columns have NaN values\n",
    "df_filtered = time_plate_info[time_plate_info[columns_to_check].isna().any(axis=1)]\n",
    "\n",
    "# Find the unique ids corresponding to those rows\n",
    "unique_ids_with_nans = df_filtered['unique_id'].unique()\n",
    "\n",
    "print(\"Unique IDs with at least one NaN in specified columns:\", unique_ids_with_nans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02afd26-fe26-49d0-8739-f6d04af720ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[plate for plate in plates if int(plate) not in time_plate_info['unique_id'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1094b26-5985-428b-ba25-d3a0015fc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_integral(df, column, new_column):\n",
    "    # Calculate the time difference within each group\n",
    "    df['time_since_begin_hour'] = df['time_since_begin_h'].dt.total_seconds() / 3600.0\n",
    "    df['time_diff'] = df.groupby('unique_id')['time_since_begin_hour'].transform(lambda x: x.diff())\n",
    "\n",
    "    # Calculate the average length density within each group\n",
    "    df['avg_length_density'] = df.groupby('unique_id')[column].transform(lambda x: x.rolling(window=2).mean())\n",
    "\n",
    "    # Calculate the \"area\" (using Trapezoidal rule) for each pair of rows within each group\n",
    "    df['area'] = df['time_diff'] * df['avg_length_density']\n",
    "\n",
    "    # Perform the integration (cumulative sum of \"area\") within each group\n",
    "    df[new_column] = df.groupby('unique_id')['area'].transform(lambda x: x.cumsum())\n",
    "\n",
    "    # Drop the helper columns if needed\n",
    "    df.drop(['time_diff', 'avg_length_density', 'area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845230ad-50da-4c6b-ad06-af58362042d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    calculate_integral(time_plate_info,f'SA_region_{i}',f'integrated_SA_{i}')\n",
    "for i in range(18):\n",
    "    calculate_integral(time_plate_info,f'length_density_region_{i}',f'integrated_L_{i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7a576-7928-4eeb-85ac-f3f9ec6e4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_to_basic_mapping = {\n",
    "    1: [1, 2],\n",
    "    2: [3, 8],\n",
    "    3: [4, 5],\n",
    "    4: [6, 7],\n",
    "    5: [9, 10],\n",
    "    6: [11, 12],\n",
    "    7: [13],\n",
    "    8: [14, 15],\n",
    "    9: [16, 17, 18]\n",
    "}\n",
    "\n",
    "# Mapping for \"simple\" to \"basic\"\n",
    "simple_to_basic_mapping = {\n",
    "    0: list(range(1, 11)),\n",
    "    1: list(range(11, 19))\n",
    "}\n",
    "sub_to_basic_mapping = {\n",
    "    0: list(range(1, 19)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745bdf5-7036-4817-8169-0e1d613f5d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import *\n",
    "from amftrack.notebooks.P_experiment.helper import get_polygons\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('presentation.mplstyle')\n",
    "\n",
    "%matplotlib widget\n",
    "C_max2 = 1.53\n",
    "\n",
    "def fit_function(x, C_max):\n",
    "    return 1+C_max * 1/x**(3/2)\n",
    "# Read the Excel file\n",
    "path = r'C:\\Users\\coren\\Documents\\PhD\\Pexperiment'\n",
    "path_excel = os.path.join(path,'summary.xlsx')\n",
    "df = pd.read_excel(path_excel)\n",
    "df['date_from_unique_id'] = pd.to_datetime(df['unique_id'].str.split('_').str[1], format='%Y%m%d')\n",
    "    \n",
    "# Convert 'day' column to datetime\n",
    "df['day_sample'] = pd.to_datetime(df['day_sample'], format='%Y%m%d')  # Update the format as necessary\n",
    "df['day_start'] = pd.to_datetime(df['start'], format='%Y%m%d')  # Update the format as necessary\n",
    "\n",
    "df['time_elapsed'] = df['day_sample'] - df['day_start']\n",
    "df['time_elapsed_day'] = df['time_elapsed'].dt.days\n",
    "df['time_since_crossing'] = df['day_sample'] - df['date_from_unique_id']\n",
    "df['t2 (day)'] = df['time_since_crossing'].dt.days\n",
    "df['t1 (day)'] = df['time_elapsed_day']-df['t2 (day)']\n",
    "df['treatment'] = df['treatment'].fillna('none')\n",
    "df['wet_weight_measured'] = df['wet weight']\n",
    "\n",
    "df['wet weight'] = df['wet weight']-df['lost weight']\n",
    "df['totP (ug)'] = df['totP (ug)'] * fit_function(df['totP (ug)'], C_max2)\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('bottom','0')\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('up','1')\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('top','1')\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('agar','0')\n",
    "\n",
    "\n",
    "\n",
    "df = df.loc[df['plate']!=487]\n",
    "df = df.loc[df['type'] == 'agar']\n",
    "df['pos'] = df['Sample_name'].str.split('-').str.get(1).astype(int)\n",
    "\n",
    "time_plate_info.sort_values(['unique_id', 'time_since_begin_h'], inplace=True)\n",
    "\n",
    "# Group by unique_id and take the last entry for each group\n",
    "last_values = time_plate_info.groupby('unique_id').last().reset_index()\n",
    "\n",
    "# Create a function to map 'pos' to the corresponding integrated_Ldens_i value\n",
    "def get_integrated_density(row):\n",
    "    unique_id = row['unique_id']\n",
    "    pos = row['pos']\n",
    "    arrangement = row['arrangement']\n",
    "    if arrangement == 'basic':\n",
    "        col_names = [f'integrated_SA_{pos-1}']\n",
    "    if arrangement == 'simple':\n",
    "        col_names = [f'integrated_SA_{basic_pos-1}' for basic_pos in simple_to_basic_mapping[pos]]\n",
    "    if arrangement == 'coarse':\n",
    "        col_names = [f'integrated_SA_{basic_pos-1}' for basic_pos in coarse_to_basic_mapping[pos]] \n",
    "    if arrangement == 'sub':\n",
    "        col_names = [f'integrated_SA_{basic_pos-1}' for basic_pos in sub_to_basic_mapping[pos]] \n",
    "    if not unique_id is np.nan:\n",
    "        last_value_row = last_values[last_values['unique_id'] == int(unique_id)]\n",
    "        return np.sum(last_value_row[col_names].values) if not last_value_row.empty else None\n",
    "    else:\n",
    "        return(None)\n",
    "df['integrated_SA'] = df.apply(get_integrated_density, axis=1)\n",
    "\n",
    "grouped = df.groupby(['plate', 'type', \"time_elapsed_day\", \"t1 (day)\", \"treatment\", 't2 (day)', \"arrangement\",\"day_start\"]).agg({\n",
    "    'totP (ug)': 'sum',\n",
    "    'wet weight': ['sum', 'median'],\n",
    "    \"wet_weight_measured\":\"sum\",\n",
    "    'dry weight': 'sum',\n",
    "    'integrated_SA':\"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "grouped.columns = ['_'.join(col).strip() if col[0] == 'wet weight' else col[0] for col in grouped.columns]\n",
    "grouped = grouped.rename(columns={\n",
    "    'wet weight_sum': 'tot_wet_weight',\n",
    "    'wet weight_median': 'wet_weight_median'\n",
    "})\n",
    "grouped['C_P'] = grouped['totP (ug)'] / grouped['tot_wet_weight']\n",
    "grouped['P_content'] = grouped['totP (ug)'] / grouped['dry weight']/1e6\n",
    "\n",
    "df['C_P'] = df['totP (ug)'] / df['wet weight']\n",
    "df['P_content'] = df['totP (ug)'] / df['dry weight']/1e6\n",
    "# df = df[df['type'] != 'sub']\n",
    "\n",
    "grouped = grouped[grouped['plate']!=487]\n",
    "grouped = grouped[grouped['plate']!=431]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae0197-dcd3-4e9c-9f45-df71a6e38664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['integrated_SA_C']=df['integrated_SA']/df['wet weight']\n",
    "# grouped = dfgrouped = df.groupby(['plate', 'type',\"time_elapsed_day\",\"t1 (day)\",\"treatment\",'t2 (day)']).agg({'totP (ug)': 'sum', 'wet weight': 'sum','dry weight' : \"sum\",'integrated_SA':\"sum\"}).reset_index()\n",
    "grouped['C_P'] = grouped['totP (ug)'] / grouped['tot_wet_weight']\n",
    "grouped['P_content'] = grouped['totP (ug)'] / grouped['dry weight']/1e6\n",
    "grouped['integrated_SA_C']=grouped['integrated_SA']/grouped['tot_wet_weight']\n",
    "tot_weights = grouped[grouped['type'].isin([\"agartot\", \"rootagartot\"])].set_index(['plate', 'type'])['wet_weight_measured'].to_dict()\n",
    "\n",
    "# Function to determine the 'measured_tot_wet_weight' based on conditions\n",
    "def get_tot_weight(row):\n",
    "    if row['type'] == 'agar' and (row['plate'], 'agartot') in tot_weights:\n",
    "        return tot_weights[(row['plate'], 'agartot')]\n",
    "    elif row['type'] == 'rootagar' and (row['plate'], 'rootagartot') in tot_weights:\n",
    "        return tot_weights[(row['plate'], 'rootagartot')]\n",
    "    else:\n",
    "        return row['wet_weight_measured']\n",
    "\n",
    "# Apply the function to get 'measured_tot_wet_weight' column\n",
    "grouped['measured_tot_wet_weight'] = grouped.apply(get_tot_weight, axis=1)\n",
    "grouped= grouped[grouped['type'] != 'rootagartot']\n",
    "grouped= grouped[grouped['type'] != 'agartot']\n",
    "# Step 1: Identify plates that don't have any rows with type \"agartot\"\n",
    "plates_with_agartot = grouped2[grouped2['type'] == 'rootagartot']['plate'].unique()\n",
    "valid_plates = grouped2[~grouped2['plate'].isin(plates_with_agartot)]\n",
    "\n",
    "# Step 2: Compute the average \"wet weight\" for type 'agar' and 'rootagar'\n",
    "average_wet_weight_agar = valid_plates[valid_plates['type'] == 'agar']['measured_tot_wet_weight'].mean()\n",
    "average_wet_weight_rootagar = valid_plates[valid_plates['type'] == 'rootagar']['measured_tot_wet_weight'].mean()\n",
    "\n",
    "# Step 3: Replace rows in the 'average weight' column accordingly\n",
    "grouped['average weight'] = None  # Initialize column with None values\n",
    "grouped.loc[grouped['type'] == 'agar', 'average weight'] = average_wet_weight_agar\n",
    "grouped.loc[grouped['type'] == 'rootagar', 'average weight'] = average_wet_weight_rootagar\n",
    "grouped.loc[grouped['type'] == 'agar', 'fullP'] = grouped.loc[grouped['type'] == 'agar', 'measured_tot_wet_weight'] *grouped.loc[grouped['type'] == 'agar', 'C_P']\n",
    "grouped.loc[grouped['type'] == 'rootagar', 'fullP'] = grouped.loc[grouped['type'] == 'rootagar', 'measured_tot_wet_weight'] *grouped.loc[grouped['type'] == 'rootagar', 'C_P']\n",
    "grouped.loc[grouped['type'] == 'root', 'fullP'] = grouped.loc[grouped['type'] == 'root', 'totP (ug)']\n",
    "totP_theory = 100\n",
    "grouped['scaling_factor'] = totP_theory/grouped.groupby('plate')['fullP'].transform('sum')\n",
    "\n",
    "# Multiply 'fullP' by the scaling factor to get 'fullP_rescaled'\n",
    "grouped['fullP_rescaled'] = grouped['fullP'] * grouped['scaling_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fec00-cd79-41d6-aed1-d193f7b50bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_agar = grouped.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7f68c-9d36-4621-8ca4-7bfe7512822d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = 1/2.54  # centimeters in inches\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (6*cm,4*cm))\n",
    "select = grouped_agar[grouped_agar['t2 (day)']<=9]\n",
    "select = select[select['treatment']=='100P']\n",
    "\n",
    "\n",
    "\n",
    "# sns.scatterplot(df,x = 'integrated_SA_C',y = 'C_P',ax = ax,hue =\"treatment\",s = 6)\n",
    "sns.scatterplot(select,x = 'integrated_SA_C',y = 'C_P',ax = ax,s=50)\n",
    "sns.regplot(select,x = 'integrated_SA_C',y = 'C_P',ax = ax,scatter = False)\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "ax.set_ylim(1.8,4.3)\n",
    "plt.ylabel('[P] \\n ($\\mu g/mL$)')\n",
    "plt.xlabel('$\\int_0^{t_f} SA(t)dt$ \\n ($\\mu m^2h/mL$)')\n",
    "plt.savefig(os.path.join(path_figure,'Figure3A.pdf'), transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d35f8c-4293-43cc-bec2-e5c35a6c0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(select['integrated_SA_C'], select['C_P'])\n",
    "slope2, intercept, r_value, p_value, std_err = stats.linregress(select['integrated_SA'], select['fullP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba473395-2ecc-4b77-9916-0c0454b2312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path_excel)\n",
    "df['date_from_unique_id'] = pd.to_datetime(df['unique_id'].str.split('_').str[1], format='%Y%m%d')\n",
    "    \n",
    "# Convert 'day' column to datetime\n",
    "df['day_sample'] = pd.to_datetime(df['day_sample'], format='%Y%m%d')  # Update the format as necessary\n",
    "df['day_start'] = pd.to_datetime(df['start'], format='%Y%m%d')  # Update the format as necessary\n",
    "\n",
    "df['time_elapsed'] = df['day_sample'] - df['day_start']\n",
    "df['time_elapsed_day'] = df['time_elapsed'].dt.days\n",
    "df['time_since_crossing'] = df['day_sample'] - df['date_from_unique_id']\n",
    "df['t2 (day)'] = df['time_since_crossing'].dt.days\n",
    "df['t1 (day)'] = df['time_elapsed_day']-df['t2 (day)']\n",
    "df['treatment'] = df['treatment'].fillna('none')\n",
    "df['wet_weight_measured'] = df['wet weight']\n",
    "\n",
    "df['wet weight'] = df['wet weight']-df['lost weight']\n",
    "df['totP (ug)'] = df['totP (ug)'] * fit_function(df['totP (ug)'], C_max2)\n",
    "\n",
    "grouped = df.groupby(['plate', 'type', \"time_elapsed_day\", \"t1 (day)\", \"treatment\", 't2 (day)', \"arrangement\",\"day_start\"]).agg({\n",
    "    'totP (ug)': 'sum',\n",
    "    'wet weight': ['sum', 'median'],\n",
    "    \"wet_weight_measured\":\"sum\",\n",
    "    'dry weight': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "grouped.columns = ['_'.join(col).strip() if col[0] == 'wet weight' else col[0] for col in grouped.columns]\n",
    "grouped = grouped.rename(columns={\n",
    "    'wet weight_sum': 'tot_wet_weight',\n",
    "    'wet weight_median': 'wet_weight_median'\n",
    "})\n",
    "grouped['C_P'] = grouped['totP (ug)'] / grouped['tot_wet_weight']\n",
    "grouped['P_content'] = grouped['totP (ug)'] / grouped['dry weight']/1e6\n",
    "\n",
    "df['C_P'] = df['totP (ug)'] / df['wet weight']\n",
    "df['P_content'] = df['totP (ug)'] / df['dry weight']/1e6\n",
    "tot_weights = grouped[grouped['type'].isin([\"agartot\", \"rootagartot\"])].set_index(['plate', 'type'])['wet_weight_measured'].to_dict()\n",
    "\n",
    "# Function to determine the 'measured_tot_wet_weight' based on conditions\n",
    "def get_tot_weight(row):\n",
    "    if row['type'] == 'agar' and (row['plate'], 'agartot') in tot_weights:\n",
    "        return tot_weights[(row['plate'], 'agartot')]\n",
    "    elif row['type'] == 'rootagar' and (row['plate'], 'rootagartot') in tot_weights:\n",
    "        return tot_weights[(row['plate'], 'rootagartot')]\n",
    "    else:\n",
    "        return row['wet_weight_measured']\n",
    "\n",
    "# Apply the function to get 'measured_tot_wet_weight' column\n",
    "grouped['measured_tot_wet_weight'] = grouped.apply(get_tot_weight, axis=1)\n",
    "# Step 1: Identify plates that don't have any rows with type \"agartot\"\n",
    "plates_with_agartot = grouped[grouped['type'] == 'rootagartot']['plate'].unique()\n",
    "valid_plates = grouped[~grouped['plate'].isin(plates_with_agartot)]\n",
    "\n",
    "# Step 2: Compute the average \"wet weight\" for type 'agar' and 'rootagar'\n",
    "average_wet_weight_agar = valid_plates[valid_plates['type'] == 'agar']['measured_tot_wet_weight'].mean()\n",
    "average_wet_weight_rootagar = valid_plates[valid_plates['type'] == 'rootagar']['measured_tot_wet_weight'].mean()\n",
    "\n",
    "# Step 3: Replace rows in the 'average weight' column accordingly\n",
    "grouped['average weight'] = None  # Initialize column with None values\n",
    "grouped.loc[grouped['type'] == 'agar', 'average weight'] = average_wet_weight_agar\n",
    "grouped.loc[grouped['type'] == 'rootagar', 'average weight'] = average_wet_weight_rootagar\n",
    "grouped.loc[grouped['type'] == 'agar', 'fullP'] = grouped.loc[grouped['type'] == 'agar', 'measured_tot_wet_weight'] *grouped.loc[grouped['type'] == 'agar', 'C_P']\n",
    "grouped.loc[grouped['type'] == 'rootagar', 'fullP'] = grouped.loc[grouped['type'] == 'rootagar', 'measured_tot_wet_weight'] *grouped.loc[grouped['type'] == 'rootagar', 'C_P']\n",
    "grouped.loc[grouped['type'] == 'root', 'fullP'] = grouped.loc[grouped['type'] == 'root', 'totP (ug)']\n",
    "totP_theory = 100\n",
    "grouped['scaling_factor'] = totP_theory/grouped.groupby('plate')['fullP'].transform('sum')\n",
    "\n",
    "# Multiply 'fullP' by the scaling factor to get 'fullP_rescaled'\n",
    "grouped['fullP_rescaled'] = grouped['fullP'] * grouped['scaling_factor']\n",
    "grouped = grouped.merge(grouped_agar[['plate','integrated_SA_C','integrated_SA']],how = \"left\",on='plate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f90f6-9226-40fb-b5bd-07e65a50c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ce388-e5f9-46d1-a5a1-b91a73f7c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "select= grouped[grouped['fullP']>0]\n",
    "select= select[select['treatment']=='100P']\n",
    "select = select[select['t2 (day)']<=9]\n",
    "select = select[select['plate']!=431]\n",
    "select = select[select['plate']!=487]\n",
    "column = 'integrated_SA_C'\n",
    "t2_values = select[column].unique()\n",
    "color_dict = {\n",
    "    'root': 'blue',\n",
    "    'agar': 'red',\n",
    "    'rootagar': 'green'\n",
    "}\n",
    "# Plotting\n",
    "fig,ax = plt.subplots(figsize = (6*cm,4*cm))\n",
    "# Unique categories in the hue column\n",
    "types = select['type'].unique()\n",
    "color_dict = {\n",
    "    'root': 'orange',\n",
    "    'agar': 'purple',\n",
    "    'rootagar': 'green'\n",
    "}\n",
    "\n",
    "# Iterate over each category\n",
    "for type_obj in types:\n",
    "    # Subset data for the category\n",
    "    subset = select[select['type'] == type_obj]\n",
    "\n",
    "    # Create a regplot for the subset\n",
    "    sns.regplot(x=subset[column], y=subset['fullP'], color = color_dict[type_obj],scatter_kws= {\"s\":50})\n",
    "\n",
    "# for t2 in sorted(t2_values):\n",
    "#     plate_data = select[select[column] == t2]\n",
    "#     for k,type_ in enumerate(['root', 'agar', 'rootagar']):\n",
    "#         value = plate_data[plate_data['type'] == type_]['fullP'].mean()\n",
    "#             # print(t2,plate_data[plate_data['type'] == type_]['plate'])\n",
    "#         ax.scatter(t2, value, color=color_dict[type_])\n",
    "#         # print(t2,value,plate_data)\n",
    "\n",
    "ax.set_ylabel('fullP Value')\n",
    "ax.set_xlabel('t2 Value')\n",
    "\n",
    "\n",
    "ax.set_ylabel('P mass (ug)')\n",
    "ax.set_xlabel('Time since crossing (day)')\n",
    "plt.ylabel('$m_P$ \\n ($\\mu g$)')\n",
    "plt.xlabel('$\\int_0^{t_f} SA(t)dt$ \\n ($\\mu m^2h$)')\n",
    "plt.savefig(os.path.join(path_figure,'Figure3B.pdf'), transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250db0e-7e9b-4d9d-ab01-3beb91b6e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
