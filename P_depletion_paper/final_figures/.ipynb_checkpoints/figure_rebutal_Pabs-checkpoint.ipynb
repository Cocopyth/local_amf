{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88220c9b-d582-42c5-ba3d-4a51f32874e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\coren\\documents\\phd\\code\\amftrack\\amftrack\\util\\dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from amftrack.util.sys import get_analysis_folders,get_time_plate_info_from_analysis,get_time_hypha_info_from_analysis,get_global_hypha_info_from_analysis, get_time_plate_info_long_from_analysis\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import cv2\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from amftrack.pipeline.final_analysis.density_wave import get_wave_fit, S, dS, wave, dwave\n",
    "import matplotlib.patches as mpatches\n",
    "from random import choice\n",
    "import matplotlib as mpl\n",
    "from amftrack.pipeline.final_analysis.density_wave import plot_single_plate,plot_single_plate_biovolume\n",
    "from amftrack.pipeline.final_analysis.hypha_speed_analysis import *\n",
    "from amftrack.util.plot import gridplot, make_stat\n",
    "%store -r path_figure\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import hashlib\n",
    "from matplotlib.patches import Ellipse\n",
    "import logging\n",
    "plt.style.use('presentation.mplstyle')\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "all_analysis_folders = get_analysis_folders()\n",
    "#for P\n",
    "plates = [\n",
    "\"416_20230705\",\n",
    "\"427_20230707\",\n",
    "\"420_20230705\",\n",
    "\"431_20230627\",\n",
    "\"474_20230807\",\n",
    "\"460_20230807\",\n",
    "\"464_20230807\",\n",
    "\"440_20230723\",\n",
    "\"436_20230717\",\n",
    "\"443_20230720\",\n",
    "\"439_20230804\",\n",
    "\"470_20230709\",\n",
    "'478_20230814', '468_20230809', '447_20230821', '487_20230922',\n",
    "       '492_20230901', '471_20230821', '486_20231009',\n",
    "       '494_20230908', '482_20230908', '495_20231013', '463_20231013',\n",
    "       '491_20231013', '481_20231005', '483_20231005',\n",
    "    '490_20231003',\n",
    "       '485_20230929',\n",
    "]\n",
    "analysis_folders = all_analysis_folders.loc[all_analysis_folders['unique_id'].isin(plates)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986351b8-85fd-4de3-ae1d-56f6d7f54313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders,time_plate_info = get_time_plate_info_from_analysis(analysis_folders,False)\n",
    "folders,time_plate_info = get_time_plate_info_long_from_analysis(analysis_folders,False)\n",
    "time_plate_info['unique_id'] = time_plate_info['unique_id'].replace(47020230709,47020230802)\n",
    "time_plate_info=time_plate_info[time_plate_info['Plate']!=431]\n",
    "# time_plate_info['time_since_begin_hour'] = time_plate_info['time_since_begin_h'].dt.total_seconds() / 3600.0\n",
    "# time_plate_info['time_since_begin_hour'] = time_plate_info['time_since_begin_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956c796-be74-4540-9725-2880279808ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "columns_to_check = [f'SA_region_{i}' for i in range(18)] + [f'length_density_region_{i}' for i in range(18)]\n",
    "\n",
    "# Filter DataFrame rows where any of the specified columns have NaN values\n",
    "df_filtered = time_plate_info[time_plate_info[columns_to_check].isna().any(axis=1)]\n",
    "\n",
    "# Find the unique ids corresponding to those rows\n",
    "unique_ids_with_nans = df_filtered['unique_id'].unique()\n",
    "\n",
    "print(\"Unique IDs with at least one NaN in specified columns:\", unique_ids_with_nans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02afd26-fe26-49d0-8739-f6d04af720ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[plate for plate in plates if int(plate) not in time_plate_info['unique_id'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1094b26-5985-428b-ba25-d3a0015fc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_integral(df, column, new_column):\n",
    "    # Calculate the time difference within each group\n",
    "    df['time_since_begin_hour'] = df['time_since_begin_h'].dt.total_seconds() / 3600.0\n",
    "    df['time_diff'] = df.groupby('unique_id')['time_since_begin_hour'].transform(lambda x: x.diff())\n",
    "\n",
    "    # Calculate the average length density within each group\n",
    "    df['avg_length_density'] = df.groupby('unique_id')[column].transform(lambda x: x.rolling(window=2).mean())\n",
    "\n",
    "    # Calculate the \"area\" (using Trapezoidal rule) for each pair of rows within each group\n",
    "    df['area'] = df['time_diff'] * df['avg_length_density']\n",
    "\n",
    "    # Perform the integration (cumulative sum of \"area\") within each group\n",
    "    df[new_column] = df.groupby('unique_id')['area'].transform(lambda x: x.cumsum())\n",
    "\n",
    "    # Drop the helper columns if needed\n",
    "    df.drop(['time_diff', 'avg_length_density', 'area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845230ad-50da-4c6b-ad06-af58362042d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    calculate_integral(time_plate_info,f'SA_region_{i}',f'integrated_SA_{i}')\n",
    "for i in range(18):\n",
    "    calculate_integral(time_plate_info,f'length_density_region_{i}',f'integrated_L_{i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7a576-7928-4eeb-85ac-f3f9ec6e4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_to_basic_mapping = {\n",
    "    1: [1, 2],\n",
    "    2: [3, 8],\n",
    "    3: [4, 5],\n",
    "    4: [6, 7],\n",
    "    5: [9, 10],\n",
    "    6: [11, 12],\n",
    "    7: [13],\n",
    "    8: [14, 15],\n",
    "    9: [16, 17, 18]\n",
    "}\n",
    "\n",
    "# Mapping for \"simple\" to \"basic\"\n",
    "simple_to_basic_mapping = {\n",
    "    0: list(range(1, 11)),\n",
    "    1: list(range(11, 19))\n",
    "}\n",
    "sub_to_basic_mapping = {\n",
    "    0: list(range(1, 19)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745bdf5-7036-4817-8169-0e1d613f5d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import *\n",
    "from amftrack.notebooks.P_experiment.helper import get_polygons\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('presentation.mplstyle')\n",
    "\n",
    "%matplotlib widget\n",
    "C_max2 = 1.53\n",
    "\n",
    "def fit_function(x, C_max):\n",
    "    return 1+C_max * 1/x**(3/2)\n",
    "# Read the Excel file\n",
    "path = r'C:\\Users\\coren\\Documents\\PhD\\Pexperiment'\n",
    "path_excel = os.path.join(path,'summary.xlsx')\n",
    "df = pd.read_excel(path_excel)\n",
    "df['date_from_unique_id'] = pd.to_datetime(df['unique_id'].str.split('_').str[1], format='%Y%m%d')\n",
    "    \n",
    "# Convert 'day' column to datetime\n",
    "df['day_sample'] = pd.to_datetime(df['day_sample'], format='%Y%m%d')  # Update the format as necessary\n",
    "df['day_start'] = pd.to_datetime(df['start'], format='%Y%m%d')  # Update the format as necessary\n",
    "\n",
    "df['time_elapsed'] = df['day_sample'] - df['day_start']\n",
    "df['time_elapsed_day'] = df['time_elapsed'].dt.days\n",
    "df['time_since_crossing'] = df['day_sample'] - df['date_from_unique_id']\n",
    "df['t2 (day)'] = df['time_since_crossing'].dt.days\n",
    "df['t1 (day)'] = df['time_elapsed_day']-df['t2 (day)']\n",
    "df['treatment'] = df['treatment'].fillna('none')\n",
    "df['wet_weight_measured'] = df['wet weight']\n",
    "\n",
    "df['wet weight'] = df['wet weight']-df['lost weight']\n",
    "df['totP (ug)'] = df['totP (ug)'] * fit_function(df['totP (ug)'], C_max2)\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('bottom','0')\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('up','1')\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('top','1')\n",
    "df['Sample_name'] = df['Sample_name'].str.replace('agar','0')\n",
    "\n",
    "\n",
    "\n",
    "df = df.loc[df['plate']!=487]\n",
    "df = df.loc[df['type'] == 'agar']\n",
    "df['pos'] = df['Sample_name'].str.split('-').str.get(1).astype(int)\n",
    "\n",
    "time_plate_info.sort_values(['unique_id', 'time_since_begin_h'], inplace=True)\n",
    "\n",
    "# Group by unique_id and take the last entry for each group\n",
    "last_values = time_plate_info.groupby('unique_id').last().reset_index()\n",
    "\n",
    "# Create a function to map 'pos' to the corresponding integrated_Ldens_i value\n",
    "def get_integrated_density(row):\n",
    "    unique_id = row['unique_id']\n",
    "    pos = row['pos']\n",
    "    arrangement = row['arrangement']\n",
    "    if arrangement == 'basic':\n",
    "        col_names = [f'integrated_SA_{pos-1}']\n",
    "    if arrangement == 'simple':\n",
    "        col_names = [f'integrated_SA_{basic_pos-1}' for basic_pos in simple_to_basic_mapping[pos]]\n",
    "    if arrangement == 'coarse':\n",
    "        col_names = [f'integrated_SA_{basic_pos-1}' for basic_pos in coarse_to_basic_mapping[pos]] \n",
    "    if arrangement == 'sub':\n",
    "        col_names = [f'integrated_SA_{basic_pos-1}' for basic_pos in sub_to_basic_mapping[pos]] \n",
    "    if not unique_id is np.nan:\n",
    "        last_value_row = last_values[last_values['unique_id'] == int(unique_id)]\n",
    "        return np.sum(last_value_row[col_names].values) if not last_value_row.empty else None\n",
    "    else:\n",
    "        return(None)\n",
    "df['integrated_SA'] = df.apply(get_integrated_density, axis=1)\n",
    "\n",
    "grouped = df.groupby(['plate', 'type', \"time_elapsed_day\", \"t1 (day)\", \"treatment\", 't2 (day)', \"arrangement\",\"day_start\"]).agg({\n",
    "    'totP (ug)': 'sum',\n",
    "    'wet weight': ['sum', 'median'],\n",
    "    \"wet_weight_measured\":\"sum\",\n",
    "    'dry weight': 'sum',\n",
    "    'integrated_SA':\"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "grouped.columns = ['_'.join(col).strip() if col[0] == 'wet weight' else col[0] for col in grouped.columns]\n",
    "grouped = grouped.rename(columns={\n",
    "    'wet weight_sum': 'tot_wet_weight',\n",
    "    'wet weight_median': 'wet_weight_median'\n",
    "})\n",
    "grouped['C_P'] = grouped['totP (ug)'] / grouped['tot_wet_weight']\n",
    "grouped['P_content'] = grouped['totP (ug)'] / grouped['dry weight']/1e6\n",
    "\n",
    "df['C_P'] = df['totP (ug)'] / df['wet weight']\n",
    "df['P_content'] = df['totP (ug)'] / df['dry weight']/1e6\n",
    "# df = df[df['type'] != 'sub']\n",
    "\n",
    "grouped = grouped[grouped['plate']!=487]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a542fa0-cc58-4573-ae78-81a5c9fd2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrangement'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae0197-dcd3-4e9c-9f45-df71a6e38664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['integrated_SA_C']=df['integrated_SA']/df['wet weight']\n",
    "# grouped = dfgrouped = df.groupby(['plate', 'type',\"time_elapsed_day\",\"t1 (day)\",\"treatment\",'t2 (day)']).agg({'totP (ug)': 'sum', 'wet weight': 'sum','dry weight' : \"sum\",'integrated_SA':\"sum\"}).reset_index()\n",
    "grouped['C_P'] = grouped['totP (ug)'] / grouped['tot_wet_weight']\n",
    "grouped['P_content'] = grouped['totP (ug)'] / grouped['dry weight']/1e6\n",
    "grouped['integrated_SA_C']=grouped['integrated_SA']/grouped['tot_wet_weight']\n",
    "tot_weights = grouped[grouped['type'].isin([\"agartot\", \"rootagartot\"])].set_index(['plate', 'type'])['wet_weight_measured'].to_dict()\n",
    "\n",
    "# Function to determine the 'measured_tot_wet_weight' based on conditions\n",
    "def get_tot_weight(row):\n",
    "    if row['type'] == 'agar' and (row['plate'], 'agartot') in tot_weights:\n",
    "        return tot_weights[(row['plate'], 'agartot')]\n",
    "    elif row['type'] == 'rootagar' and (row['plate'], 'rootagartot') in tot_weights:\n",
    "        return tot_weights[(row['plate'], 'rootagartot')]\n",
    "    else:\n",
    "        return row['wet_weight_measured']\n",
    "\n",
    "# Apply the function to get 'measured_tot_wet_weight' column\n",
    "grouped['measured_tot_wet_weight'] = grouped.apply(get_tot_weight, axis=1)\n",
    "grouped= grouped[grouped['type'] != 'rootagartot']\n",
    "grouped= grouped[grouped['type'] != 'agartot']\n",
    "# Step 1: Identify plates that don't have any rows with type \"agartot\"\n",
    "plates_with_agartot = grouped[grouped['type'] == 'rootagartot']['plate'].unique()\n",
    "valid_plates = grouped[~grouped['plate'].isin(plates_with_agartot)]\n",
    "\n",
    "# Step 2: Compute the average \"wet weight\" for type 'agar' and 'rootagar'\n",
    "average_wet_weight_agar = valid_plates[valid_plates['type'] == 'agar']['measured_tot_wet_weight'].mean()\n",
    "average_wet_weight_rootagar = valid_plates[valid_plates['type'] == 'rootagar']['measured_tot_wet_weight'].mean()\n",
    "\n",
    "# Step 3: Replace rows in the 'average weight' column accordingly\n",
    "grouped['average weight'] = None  # Initialize column with None values\n",
    "grouped.loc[grouped['type'] == 'agar', 'average weight'] = average_wet_weight_agar\n",
    "grouped.loc[grouped['type'] == 'rootagar', 'average weight'] = average_wet_weight_rootagar\n",
    "grouped.loc[grouped['type'] == 'agar', 'fullP'] = grouped.loc[grouped['type'] == 'agar', 'measured_tot_wet_weight'] *grouped.loc[grouped['type'] == 'agar', 'C_P']\n",
    "grouped.loc[grouped['type'] == 'rootagar', 'fullP'] = grouped.loc[grouped['type'] == 'rootagar', 'measured_tot_wet_weight'] *grouped.loc[grouped['type'] == 'rootagar', 'C_P']\n",
    "grouped.loc[grouped['type'] == 'root', 'fullP'] = grouped.loc[grouped['type'] == 'root', 'totP (ug)']\n",
    "totP_theory = 100\n",
    "grouped['scaling_factor'] = totP_theory/grouped.groupby('plate')['fullP'].transform('sum')\n",
    "\n",
    "# Multiply 'fullP' by the scaling factor to get 'fullP_rescaled'\n",
    "grouped['fullP_rescaled'] = grouped['fullP'] * grouped['scaling_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86562c2b-2665-405c-adbc-9cad4a130c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "select= grouped[grouped['fullP']>0]\n",
    "select= select[select['treatment']=='100P']\n",
    "select = select[select['plate']!=431]\n",
    "select = select[select['plate']!=487]\n",
    "\n",
    "t2_values = select['t2 (day)'].unique()\n",
    "color_dict = {\n",
    "    'root': 'blue',\n",
    "    'agar': 'red',\n",
    "    'rootagar': 'green'\n",
    "}\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "blues = []\n",
    "reds = []\n",
    "greens = []\n",
    "t2s = []\n",
    "for t2 in sorted(t2_values):\n",
    "    plate_data = select[select['t2 (day)'] == t2]\n",
    "    \n",
    "    bottom = 0\n",
    "    k=0\n",
    "    for type_ in ['root', 'agar', 'rootagar']:\n",
    "        value = plate_data[plate_data['type'] == type_]['fullP_rescaled'].mean()\n",
    "            # print(t2,plate_data[plate_data['type'] == type_]['plate'])\n",
    "        ax.bar(t2, value, bottom=bottom, color=color_dict[type_])\n",
    "        bottom += value\n",
    "   \n",
    "        if k==0:\n",
    "            blues.append(bottom)\n",
    "        elif k==1:\n",
    "            reds.append(bottom)\n",
    "        else:\n",
    "            greens.append(bottom)\n",
    "        k+=1\n",
    "    t2s.append(t2)\n",
    "ax.fill_between(t2s,blues,color=\"blue\",alpha = 0.3)\n",
    "ax.fill_between(t2s,blues,reds,color=\"red\",alpha = 0.3)\n",
    "ax.fill_between(t2s,greens,reds,color=\"green\",alpha = 0.3)\n",
    "\n",
    "# Setting labels and title\n",
    "ax.set_ylabel('fullP Value')\n",
    "ax.set_xlabel('t2 Value')\n",
    "ax.set_ylim(0,100)\n",
    "color_dict = {\n",
    "    'root': 'blue',\n",
    "    'fungal agar': 'red',\n",
    "    'root agar': 'green'\n",
    "}\n",
    "legend_elements = [Line2D([0], [0], color=color_dict[type_], lw=4, label=type_) for type_ in color_dict.keys()]\n",
    "ax.legend(handles=legend_elements)\n",
    "ax.set_ylabel('P mass share (%)')\n",
    "ax.set_xlabel('Time since crossing (day)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d7541-599f-4f42-9dc3-c92b0c356d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_r_value(row):\n",
    "    if row['arrangement'] == 'basic':\n",
    "        if 1 <= row['pos'] <= 5:\n",
    "            return 0\n",
    "        elif 6 <= row['pos'] <= 10:\n",
    "            return 1\n",
    "        elif 11 <= row['pos'] <= 15:\n",
    "            return 2\n",
    "        elif 16 <= row['pos'] <= 18:\n",
    "            return 3\n",
    "    elif row['arrangement'] == 'coarse':\n",
    "        if 1 <= row['pos'] <= 3:\n",
    "            return 0\n",
    "        elif 4 <= row['pos'] <= 5:\n",
    "            return 1\n",
    "        elif 6 <= row['pos'] <= 8:\n",
    "            return 2\n",
    "        elif row['pos'] == 9:\n",
    "            return 3\n",
    "    elif row['arrangement'] == 'simple':\n",
    "        if row['pos'] == 0:\n",
    "            return 0.5\n",
    "        elif row['pos'] == 1:\n",
    "            return 2.5\n",
    "    return None  # Default case if none of the conditions are met\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['r_value'] = df.apply(set_r_value, axis=1)\n",
    "grouped_r = df.groupby(['plate', 'type', \"time_elapsed_day\", \"t1 (day)\", \"treatment\", 't2 (day)', \"arrangement\",\"day_start\",\"r_value\"]).agg({\n",
    "    'totP (ug)': 'sum',\n",
    "    'wet weight': ['sum', 'median'],\n",
    "    \"wet_weight_measured\":\"sum\",\n",
    "    'dry weight': 'sum',\n",
    "    'integrated_SA':\"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "grouped_r.columns = ['_'.join(col).strip() if col[0] == 'wet weight' else col[0] for col in grouped_r.columns]\n",
    "grouped_r = grouped_r.rename(columns={\n",
    "    'wet weight_sum': 'tot_wet_weight',\n",
    "    'wet weight_median': 'wet_weight_median'\n",
    "})\n",
    "grouped_r['C_P'] = grouped_r['totP (ug)'] / grouped_r['tot_wet_weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47304cd-be30-413f-ad64-c225a662fced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "df = df[df['plate']!=431]\n",
    "select = df[df['treatment']=='100P']\n",
    "select = select[select['t2 (day)']<=9]\n",
    "select = select[select['arrangement'].isin(['coarse','basic'])]\n",
    "\n",
    "\n",
    "sns.scatterplot(select,x = 'integrated_SA_C',y = 'C_P',ax = ax,hue =\"r_value\")\n",
    "# ax.set_xscale('log')\n",
    "# ax.hlines(mean0P,0,2e9, color = \"grey\",label = \"test samples (0P)\")\n",
    "ax.set_ylim(0,4.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d01d42-b8a5-470e-9361-2ea7c73c737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_r[grouped_r['r_value']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922af71-6f9e-4e59-b850-7c6106cadf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "df = grouped_r[grouped_r['plate']!=431]\n",
    "select = grouped_r[grouped_r['treatment']=='100P']\n",
    "select = select[select['t2 (day)']<=9]\n",
    "select = select[select['C_P']<=5]\n",
    "\n",
    "select = select[select['arrangement'].isin(['coarse','basic'])]\n",
    "\n",
    "\n",
    "# sns.scatterplot(select,x = 't2 (day)',y = 'C_P',ax = ax,hue =\"r_value\")\n",
    "sns.lineplot(select,x = 't2_coarse',y = 'C_P',ax = ax,hue =\"r_value\",estimator = \"mean\")\n",
    "# sns.lmplot(select,x = 't2 (day)',y = 'C_P',hue =\"r_value\")\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "# ax.hlines(mean0P,0,2e9, color = \"grey\",label = \"test samples (0P)\")\n",
    "ax.set_ylim(2,4.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195175e-273e-4026-a47d-8511c35da26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_r['t2_coarse'] = grouped_r['t2 (day)']//3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b93a22-5b78-4d69-8033-81553af61dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "select = grouped_r[grouped_r['treatment']=='100P']\n",
    "select = select[select['t2 (day)']<=30]\n",
    "select = select[select['C_P']<=5]\n",
    "\n",
    "select = select[select['arrangement'].isin(['coarse','basic','simple'])]\n",
    "# select = select[select['arrangement'].isin(['coarse','basic'])]\n",
    "\n",
    "\n",
    "\n",
    "# sns.scatterplot(select,x = 'r_value',y = 'C_P',ax = ax,hue =\"t2 (day)\")\n",
    "sns.lineplot(select,x = 'r_value',y = 'C_P',ax = ax,hue =\"t2_coarse\",estimator = \"mean\",)\n",
    "# sns.lineplot(select,x = 'r_value',y = 'C_P',ax = ax,estimator = \"median\",)\n",
    "\n",
    "sns.lmplot(select,x = 'r_value',y = 'C_P',hue =\"t2_coarse\",ci=None,scatter=False)\n",
    "\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "# ax.hlines(mean0P,0,2e9, color = \"grey\",label = \"test samples (0P)\")\n",
    "ax.set_ylim(2,4.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
